# poetry install --extras "ui llms-llama-cpp vector-stores-qdrant embeddings-huggingface"
server:
  env_name: ${APP_ENV:local}

llm:
  mode: llamacpp
  # Should be matching the selected model
  max_new_tokens: 8192
  context_window: 8192
  tokenizer: meta-llama/Meta-Llama-3-8B-Instruct
  prompt_style: "llama-3"

llamacpp:
  llm_hf_repo_id: bartowski/Llama-3-ChatQA-1.5-8B-GGUF
  llm_hf_model_file: ChatQA-1.5-8B-Q6_K.gguf

embedding:
  # Should be matching the value above in most cases
  mode: huggingface
  ingest_mode: simple

huggingface:
  embedding_hf_model_name: Snowflake/snowflake-arctic-embed-l

vectorstore:
  database: qdrant

qdrant:
  path: local_data/private_gpt/qdrant
